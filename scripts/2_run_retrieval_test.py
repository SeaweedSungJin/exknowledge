import os
import yaml
from PIL import Image

# saliency_vlm_core í´ë”ì˜ ëª¨ë“ˆë“¤ì„ ì„í¬íŠ¸í•˜ê¸° ìœ„í•´ ê²½ë¡œ ì¶”ê°€
import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from saliency_vlm_core.image_processing import pre_normalize_image_size
from saliency_vlm_core.saliency import SaliencyMapper
from saliency_vlm_core.retriever import WikiRetriever  # â˜…â˜…â˜… ìƒˆë¡œ ë§Œë“  WikiRetriever ì„í¬íŠ¸ â˜…â˜…â˜…
from saliency_vlm_core.llava_vqa import LLaVAVQA

def main():
    # 1. ì„¤ì • íŒŒì¼ ë¡œë“œ
    print("--- ë‹¨ê³„ 1: ì„¤ì • íŒŒì¼ ë¡œë“œ ---")
    with open("configs/default_config.yaml", 'r') as f:
        config = yaml.safe_load(f)
    print("ì„¤ì • ë¡œë“œ ì™„ë£Œ.\n")

    # â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
    # â˜…â˜…â˜… 2. WikiRetriever ê°ì²´ ìƒì„± (ëª¨ë¸, ë°ì´í„° ë¡œë”©) â˜…â˜…â˜…
    # â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
    # ì´ í•œ ì¤„ë¡œ ëª¨ë¸, í”„ë¡œì„¸ì„œ, FAISS ì¸ë±ìŠ¤, ìœ„í‚¤ ë°ì´í„°ê°€ ëª¨ë‘ ë¡œë“œë©ë‹ˆë‹¤.
    retriever = WikiRetriever(config)

    # 3. ì´ë¯¸ì§€ ì²˜ë¦¬ ë° ìµœì¢… ì¿¼ë¦¬ ë²¡í„° ìƒì„±
    print("--- ë‹¨ê³„ 3: ì´ë¯¸ì§€ ì²˜ë¦¬ ë° ìµœì¢… ì¿¼ë¦¬ ë²¡í„° ìƒì„± ---")
    image_path = os.path.join(config['data_dir'], config['image_dir'], config['image_filename'])
    original_image = Image.open(image_path).convert("RGB")
    
    # ì‚¬ì „ ì •ê·œí™”
    normalized_image = pre_normalize_image_size(original_image, target_size=config['pre_normalize_size'])
    
    # SaliencyMapper ê°ì²´ ìƒì„± ë° ì‹¤í–‰
    # ì´ì œ model, processor, deviceë¥¼ retriever ê°ì²´ë¡œë¶€í„° ê°€ì ¸ì˜µë‹ˆë‹¤.
    saliency_mapper = SaliencyMapper(retriever.model, retriever.processor, retriever.device)
    final_image_to_encode = saliency_mapper.get_saliency_cropped_image(
        image=normalized_image,
        query=config['saliency_query'],
        window_size=config['window_size'],
        stride=config['stride'],
        keep_top_percent=config['keep_top_percent']
    )
    
    # â˜…â˜…â˜… ìµœì¢… ì´ë¯¸ì§€ë¥¼ retrieverë¥¼ í†µí•´ ì¸ì½”ë”© â˜…â˜…â˜…
    query_vector = retriever.encode_image(final_image_to_encode)
    print("ìµœì¢… ì¿¼ë¦¬ ë²¡í„° ìƒì„± ì™„ë£Œ.\n")

    # â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
    # â˜…â˜…â˜… 4. Retrieverë¥¼ í†µí•´ FAISS ê²€ìƒ‰ ë° ê²°ê³¼ ì¶œë ¥ â˜…â˜…â˜…
    # â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
    print("--- ë‹¨ê³„ 4: ìµœì¢… ë²¡í„°ë¡œ ìœ„í‚¤í”¼ë””ì•„ ë¬¸ì„œ ê²€ìƒ‰ ---")
    results = retriever.search(query_vector, top_k=config['top_k'])
    

    # ê°€ì¥ ë†’ì€ ìœ ì‚¬ë„ë¥¼ ë³´ì´ëŠ” ë¬¸ì„œì˜ ì¼ë¶€ë§Œ ì‚¬ìš©
    wiki_context = results[0]['text'] if results else ""

    # VQA ëª¨ë¸ ì´ˆê¸°í™” ë° ì§ˆë¬¸ ìˆ˜í–‰
    llava = LLaVAVQA(model_id=config.get('vlm_model_id', 'llava-hf/llava-1.5-7b-hf'))
    answer = llava.answer(final_image_to_encode, config.get('vqa_question', ''), wiki_context)
    print("VQA Answer:", answer)
    
    """    print("\n--- ìµœì¢… ê²€ìƒ‰ ê²°ê³¼ ---")
    if not results:
        print("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        for res in results:
            print(f"ğŸ” ìˆœìœ„ {res['rank']}: {res['title']}")
            print(f"âœ¨ ìœ ì‚¬ë„: {res['similarity']:.4f}")
            text_preview = res['text'].replace("\n", " ").strip()
            print(f"ğŸ“– ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°:\n{text_preview[:250]}...\n")
    """


if __name__ == "__main__":
    main()
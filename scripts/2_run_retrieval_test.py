import os
import yaml
from PIL import Image

# saliency_vlm_core í´ë”ì˜ ëª¨ë“ˆë“¤ì„ ì„í¬íŠ¸í•˜ê¸° ìœ„í•´ ê²½ë¡œ ì¶”ê°€
import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
from saliency_vlm_core.image_processing import pre_normalize_image_size
from saliency_vlm_core.saliency import SaliencyMapper
from saliency_vlm_core.retriever import WikiRetriever  
from saliency_vlm_core.llava_vqa import LLaVAVQA

def main():
    # 1. ì„¤ì • íŒŒì¼ ë¡œë“œ
    print("--- ì„¤ì • íŒŒì¼ ë¡œë“œ ---")
    with open("configs/default_config.yaml", "r") as f:
        config = yaml.safe_load(f)
    print("ì„¤ì • ë¡œë“œ ì™„ë£Œ.\n")

    # WikiRetriever ê°ì²´ ìƒì„± (ëª¨ë¸, ë°ì´í„° ë¡œë”©) 
    # ì´ í•œ ì¤„ë¡œ ëª¨ë¸, í”„ë¡œì„¸ì„œ, FAISS ì¸ë±ìŠ¤, ìœ„í‚¤ ë°ì´í„°ê°€ ëª¨ë‘ ë¡œë“œë©ë‹ˆë‹¤.
    retriever = WikiRetriever(config)

    # ì´ë¯¸ì§€ ì²˜ë¦¬ ë° ìµœì¢… ì¿¼ë¦¬ ë²¡í„° ìƒì„±
    print("--- ì´ë¯¸ì§€ ì²˜ë¦¬ ë° ìµœì¢… ì¿¼ë¦¬ ë²¡í„° ìƒì„± ---")
    image_path = os.path.join(
        config["data_dir"], config["image_dir"], config["image_filename"]
    )
    original_image = Image.open(image_path).convert("RGB")
    
    # ì‚¬ì „ ì •ê·œí™”
    normalized_image = pre_normalize_image_size(
        original_image, target_size=config["pre_normalize_size"]
    )    
    # SaliencyMapper ê°ì²´ ìƒì„± ë° ì‹¤í–‰
    # ì´ì œ model, processor, deviceë¥¼ retriever ê°ì²´ë¡œë¶€í„° ê°€ì ¸ì˜µë‹ˆë‹¤.
    saliency_mapper = SaliencyMapper(
        retriever.model, retriever.processor, retriever.device
    )
    final_image_to_encode = saliency_mapper.get_saliency_cropped_image(
        image=normalized_image,
        query=config["saliency_query"],
        window_size=config["window_size"],
        stride=config["stride"],
        keep_top_percent=config["keep_top_percent"],
    )
    
    # ìµœì¢… ì´ë¯¸ì§€ë¥¼ retrieverë¥¼ í†µí•´ ì¸ì½”ë”©
    query_vector = retriever.encode_image(final_image_to_encode)
    print("ìµœì¢… ì¿¼ë¦¬ ë²¡í„° ìƒì„± ì™„ë£Œ.\n")

    # Retrieverë¥¼ í†µí•´ FAISS ê²€ìƒ‰ ë° ê²°ê³¼ ì¶œë ¥ 
    print("--- ìµœì¢… ë²¡í„°ë¡œ ìœ„í‚¤í”¼ë””ì•„ ë¬¸ì„œ ê²€ìƒ‰ ---")
    results = retriever.search(query_vector, top_k=config["top_k"])
    # ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , ê°€ì¥ ìœ ì‚¬ë„ê°€ ë†’ì€ ë¬¸ì„œì˜ ì œëª©ì„ 'title'ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
    if results:
        top_result = results[0]
        print(f"ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ ì œëª©ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤: '{top_result['title']}'\n")
        
        #~~~~~~~~~~
        # ìˆ˜ì •ëœ ë¶€ë¶„: ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì¶•ì•½ ë¡œì§ ì¶”ê°€, ì„ì‹œì½”ë“œì„
        
        # 1. ë¬¸ì„œ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        full_text = top_result["text"]
        
        # 2. ì„¤ì • íŒŒì¼ì—ì„œ ìµœëŒ€ ê¸¸ì´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤ (ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ 1000 ì‚¬ìš©).
        max_len = config.get("max_context_chars", 1000)
        
        # 3. íŒŒì´ì¬ ë¬¸ìì—´ ìŠ¬ë¼ì´ì‹±ì„ ì´ìš©í•´ ì•ì—ì„œë¶€í„° max_len ë§Œí¼ë§Œ ì˜ë¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        wiki_context = full_text[:max_len]
        
        # 4. ì‚¬ìš©ìì—ê²Œ ì–´ë–»ê²Œ ì¶•ì•½ë˜ì—ˆëŠ”ì§€ ì•Œë ¤ì£¼ëŠ” ë¡œê·¸ ì¶œë ¥
        print(f"ì»¨í…ìŠ¤íŠ¸ë¥¼ {max_len}ìë¡œ ì¶•ì•½í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤:")
        print(f'"""\n{wiki_context}...\n"""\n')
    else:
        print("ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.\n")
        #~~~~~~~~~~


    # VQA ëª¨ë¸ ì´ˆê¸°í™” ë° ì§ˆë¬¸ ìˆ˜í–‰
    llava = LLaVAVQA(model_id=config.get("vlm_model_id", "llava-hf/llava-1.5-7b-hf"))
    answer = llava.answer(
        final_image_to_encode, config.get("vqa_question", ""), wiki_context
    )
    print("VQA Answer:", answer)
    
    """    print("\n--- ìµœì¢… ê²€ìƒ‰ ê²°ê³¼ ---")
    if not results:
        print("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        for res in results:
            print(f"ğŸ” ìˆœìœ„ {res['rank']}: {res['title']}")
            print(f"âœ¨ ìœ ì‚¬ë„: {res['similarity']:.4f}")
            text_preview = res['text'].replace("\n", " ").strip()
            print(f"ğŸ“– ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°:\n{text_preview[:250]}...\n")
    """


if __name__ == "__main__":
    main()